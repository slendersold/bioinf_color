{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import zarr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = tifffile.imread('./Calib_Polaris_Scan3.qptiff', aszarr=True)\n",
    "zarr_pyramids = zarr.open(store, mode='r')\n",
    "image = np.array(zarr_pyramids[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(image):\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary_image = cv2.adaptiveThreshold(image_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    return(binary_image)\n",
    "\n",
    "image_processed = image_preprocessing(image)\n",
    "plt.imshow(image_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Rectangle and its points (for all recognized rectangles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fing_rectangle_pts(image):\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rectangle_pts = []\n",
    "    for contour in contours:\n",
    "        epsilon = 0.03 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        if len(approx) == 4 and cv2.contourArea(approx) > 1000:\n",
    "            pts = approx.reshape(-1, 2)\n",
    "            pts = np.array(pts, dtype=np.float32)\n",
    "            rectangle_pts.append(pts)\n",
    "            \n",
    "    return(rectangle_pts)\n",
    "\n",
    "rectangle_pts = fing_rectangle_pts(image_processed)\n",
    "rectangle_pts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Aligned picture (if rectangle is rotated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will need **src_pts** (source points), **w** and **h** - widht and height of this rectangle (based on source points) and **dst_pts** (destination points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2 # for first rectangle\n",
    "src_pts = rectangle_pts[i]\n",
    "\n",
    "def find_dst_pts(src_pts):\n",
    "    w = abs((src_pts[0][0]+src_pts[1][0])/2 - (src_pts[2][0]+src_pts[3][0])/2)\n",
    "    h = abs((src_pts[0][1]+src_pts[3][1])/2 - (src_pts[1][1]+src_pts[2][1])/2)\n",
    "    return w,h\n",
    "\n",
    "w, h = find_dst_pts(src_pts)\n",
    "print(w, h)\n",
    "dst_pts = np.array([[0, 0], [0, h],  [w, h], [w, 0]], dtype=np.float32)\n",
    "\n",
    "# lets transform rectangle using src_pts, w, h, dst_pts\n",
    "M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "warp = cv2.warpPerspective(image, M, (int(w), int(h)))\n",
    "\n",
    "if warp.shape[0] < warp.shape[1]: # for CA\n",
    "    warp = warp[int(h*0.3):-int(h*0.3),int(w*0.3):-int(w*0.3),:]\n",
    "\n",
    "plt.imshow(warp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. And we can also achieve aligned picture in high resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 2 # lets go from 6 layer to 2\n",
    "image_high_res = np.array(zarr_pyramids[6-(6-layer)])\n",
    "\n",
    "\n",
    "# lets find src_pts, w, h, dst_pts\n",
    "\n",
    "coef = 2**(6-layer)\n",
    "src_pts = src_pts * coef #src_pts\n",
    "\n",
    "w, h = w * coef, h * coef # w, h\n",
    "dst_pts = dst_pts * coef # dst_pts\n",
    "\n",
    "# and transform\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "warp = cv2.warpPerspective(image_high_res, M, (int(w), int(h)))\n",
    "\n",
    "if warp.shape[0] < warp.shape[1]: # for CA\n",
    "    warp = warp[int(h*0.3):-int(h*0.3),int(w*0.3):-int(w*0.3),:]\n",
    "\n",
    "plt.imshow(warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
